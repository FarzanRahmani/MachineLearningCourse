{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install gdown -q\n!gdown --id 1QR76tqp0qmPIXVchwue4cSz0_y3Xp_Bm --output dataset.zip\n!unzip dataset.zip -d dataset","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from ultralytics import YOLO\nmodel = YOLO(\"yolov8s.pt\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install ultralytics","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom PIL import Image\nfrom torchvision.transforms import ToTensor\n\n\nimg = Image.open('/kaggle/working/dataset/test_images/image_0014.png')\nresults = model(img)\n\nresults[0].show()\n\nprint(results[0].boxes[0].xyxy.tolist()[0]) \n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"zebel1 = Image.open('/kaggle/working/dataset/zebel/1.png')\nzebel2 = Image.open('/kaggle/working/dataset/zebel/2.png')\nzebel3 = Image.open('/kaggle/working/dataset/zebel/3.png')\n\nwidth1, height1 = zebel1.size\nwidth2, height2 = zebel2.size\nwidth3, height3 = zebel3.size\n\nprint(f\"Image 1: Width = {width1}, Height = {height1}\")\nprint(f\"Image 2: Width = {width2}, Height = {height2}\")\nprint(f\"Image 3: Width = {width3}, Height = {height3}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\nimport shutil\ndataset_dir = '/kaggle/working/dataset/zebel_dataset'\n\nos.makedirs(f\"{dataset_dir}/images\", exist_ok=True)\nos.makedirs(f\"{dataset_dir}/labels\", exist_ok=True)\n\nshutil.copy('/kaggle/working/dataset/zebel/1.png', f\"{dataset_dir}/images/1.png\")\nshutil.copy('/kaggle/working/dataset/zebel/2.png', f\"{dataset_dir}/images/2.png\")\nshutil.copy('/kaggle/working/dataset/zebel/3.png', f\"{dataset_dir}/images/3.png\")\n\n# Create corresponding label files for each image (you can adjust the bounding boxes as needed)\ndef create_label_file(image_name, width, height):\n    label_file = f\"{dataset_dir}/labels/{image_name.split('.')[0]}.txt\"\n    with open(label_file, 'w') as file:\n        # Example annotation for \"zebel_class\" (class_id=0)\n        # x_center, y_center, width, height are normalized by the image dimensions\n        # Here we use a dummy bounding box, you should modify this as per your labels\n        # Assuming a box at the center of the image\n        x_center = 0.5 * width  # Normalized to [0, 1]\n        y_center = 0.5 * height\n        bbox_width = width  # Normalized width of the bounding box\n        bbox_height = height  # Normalized height of the bounding box\n        file.write(f\"0 {x_center} {y_center} {bbox_width} {bbox_height}\\n\")\n\n# Create labels for each image\ncreate_label_file('1.png', width1, height1)\ncreate_label_file('2.png', width2, height2)\ncreate_label_file('3.png', width3, height3)\n\n# Create data.yaml for YOLO\ndata_yaml = {\n    'train': f'{dataset_dir}/images',\n    'val': f'{dataset_dir}/images',\n    'nc': 1,  # Number of classes (1 class in this case)\n    'names': ['zebel_class'],  # List of class names\n}\n\n# Save the data.yaml file\nimport yaml\nwith open(f'{dataset_dir}/data.yaml', 'w') as yaml_file:\n    yaml.dump(data_yaml, yaml_file)\n\nprint(f\"Dataset directory structure created at: {dataset_dir}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from ultralytics import YOLO\n\n# Define your custom class (e.g., \"zebel_class\")\nclass_names = [\"zebel_class\"]\n\n# Initialize the model\nmodel = YOLO(\"yolov8s.pt\")\n\n# Dataset path\ndataset_path = '/kaggle/working/dataset/zebel_dataset'\n\n# Create the dataset YAML file\n# You need to create a YAML file that specifies the paths for training and validation images and labels\ndataset_yaml = {\n    'train': f'{dataset_path}/images',  # Path to the train images\n    'val': f'{dataset_path}/images',  # Path to the train images\n    'nc': 1,                            # Number of classes\n    'names': class_names                # List of class names\n}\n\n# Save the YAML file\nwith open(f'{dataset_path}/data.yaml', 'w') as yaml_file:\n    yaml.dump(dataset_yaml, yaml_file)\n\n# Train the model with custom dataset\nmodel.train(\n    data=f'{dataset_path}/data.yaml',  # Path to the dataset YAML file\n    epochs=10,                         # Number of training epochs\n    batch=4,                           # Batch size\n    imgsz=640,                         # Image size (you can experiment with this)\n    classes=[0],                       # List of classes to train (index 0 for \"zebel_class\")\n    name=\"zebel_class_model\"            # Name of the model checkpoint\n)\n\n# After training, you can test the model again\nmodel.eval()\n\n# Testing with one image from the validation set\nimg = Image.open('/kaggle/working/dataset/test_images/image_0014.png')\nresults = model(img)\n\n# Show the results\nresults[0].show()\n\n# Print the bounding box of the first detection\nprint(results[0].boxes[0].xyxy.tolist()[0])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\n# Path to the directory containing test images\ntest_images_dir = '/kaggle/working/dataset/test_images'\n\n# Get a list of image filenames in the directory\nimage_names = [f for f in os.listdir(test_images_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n\n# Print the image names\nprint(image_names)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Assuming the model has been loaded and the image names are available\nimport math\nimport numpy as np\nll=[]\ncount = 0\nfor name in image_names:\n    img = Image.open(test_images_dir + '/' + name)\n    results = model(img)\n    confmax1 = 0\n    confmax2 = 0\n    xx1 = yy1 = xx2 = yy2 = -1 \n    degree = 0\n    # Print the bounding box, class name, and confidence for each detection\n    for i, box in enumerate(results[0].boxes):\n        x1, y1, x2, y2 = box.xyxy.tolist()[0]\n        class_id = box.cls.item()  # Get the class index for the bounding box\n        class_name = results[0].names[class_id]  # Map class index to class name\n        confidence = box.conf.item()  # Get the confidence score for the box\n\n        if (class_name == 'person' or class_name == 'kite') and confidence >= confmax1:\n            confmax1 = confidence\n            xx1 = (x1 + x2)/2 \n            yy1 = (y1 + y2)/2\n\n        if class_name == 'airplane' and confidence >= confmax2:\n            confmax2 = confidence\n            xx2 = (x1 + x2)/2 \n            yy2 = (y1 + y2)/2\n\n    if xx1!=-1 and xx2!=-1:\n\n        degree = math.atan((yy2 - yy1)/ np.abs(xx1-xx2))\n    else:\n        if xx2 != -1:\n            degree = math.atan((yy2 - 150)/ np.abs(400-xx2))\n        elif xx1 != -1:\n            degree = math.atan((150 - yy1)/ np.abs(xx1-20))\n        count+=1\n        \n    print(degree*180/np.pi)\n\n\n    results[0].show()\n\n    ll.append(-degree*180/np.pi)    \n        # print(f\"Image: {name}, Box {i+1}:\")\n        # print(f\"Coordinates: ({x1}, {y1}), ({x2}, {y2})\")\n        # print(f\"Class ID: {class_id}, Class Name: {class_name}\")\n        # print(f\"Confidence: {confidence:.4f}\")  # Print confidence with 4 decimal places\n    ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import csv\n\n# Prepare the CSV file\ncsv_file_path = \"/kaggle/working/dataset/detected_labels.csv\"\nheader = [\"index\", \"file_name\", \"label\"]\n\n# Initialize the data list\ndata = []\n\n# Assuming the model has been loaded and the image names are available\nindex = 0  # To keep track of row index in the CSV\n    \nwith open(csv_file_path, mode='w', newline='') as file:\n    writer = csv.writer(file)\n    writer.writerow(image_names)  # Write the header row\n    writer.writerows(ll)  # Write the data rows\n\nprint(f\"CSV file saved at {csv_file_path}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"count","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(ll)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# ll = list(map(int, ll))\n\ndf = pd.DataFrame({\n    'file_name': image_names,\n    'degree': ll\n})\n\ndf = df.sort_values(by='file_name')\n\n# df = df.reset_index(drop=True)\n\ncsv_file_path = '/kaggle/working/submission.csv'\ndf.to_csv(csv_file_path, index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}