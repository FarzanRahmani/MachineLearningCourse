{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7845742,"sourceType":"datasetVersion","datasetId":4600270},{"sourceId":7845904,"sourceType":"datasetVersion","datasetId":4600399}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":17879.671693,"end_time":"2024-12-18T22:11:27.581599","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-12-18T17:13:27.909906","version":"2.6.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"b960f341da70434eb5bb2f31a343fb42":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f7cf88d749194b76b179b7b7760eb4fc","IPY_MODEL_8b96faa300d041cb93fd08ba5004fd58","IPY_MODEL_952b013f107c44d28aecfdefcdd7c75f"],"layout":"IPY_MODEL_4d96bf61c21c4bc3b4350a99ef740c58"}},"f7cf88d749194b76b179b7b7760eb4fc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3abd1a8fd5174463ae1c7f694c0c713a","placeholder":"​","style":"IPY_MODEL_c50f5072a94a403b8065bdee2118ca58","value":"Map: 100%"}},"8b96faa300d041cb93fd08ba5004fd58":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2da916168417474c90f852f8c83f20cc","max":59999,"min":0,"orientation":"horizontal","style":"IPY_MODEL_62a342a105e143c1b371718ce75acf21","value":59999}},"952b013f107c44d28aecfdefcdd7c75f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f0d1bc94f304ab79421f7e65d178bf0","placeholder":"​","style":"IPY_MODEL_bde48f1a3ab4497882576d5d2b9b31ef","value":" 59999/59999 [00:05&lt;00:00, 12496.21 examples/s]"}},"4d96bf61c21c4bc3b4350a99ef740c58":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3abd1a8fd5174463ae1c7f694c0c713a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c50f5072a94a403b8065bdee2118ca58":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2da916168417474c90f852f8c83f20cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62a342a105e143c1b371718ce75acf21":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4f0d1bc94f304ab79421f7e65d178bf0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bde48f1a3ab4497882576d5d2b9b31ef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c4ecfc272f5d49fa8692582a69b7e61c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7ec31a50f0524ed8b3bd515577a0c038","IPY_MODEL_c7f1596aee54403680a00c37fb009681","IPY_MODEL_b26b31daee2349e58dd7d4b80345e528"],"layout":"IPY_MODEL_8ac084fcfaeb433ea59ec1647ab580b9"}},"7ec31a50f0524ed8b3bd515577a0c038":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8b90e2fdaa9489dad98e78e3f9ff79a","placeholder":"​","style":"IPY_MODEL_8fa18a97ef8c411a828c629e2c9795a7","value":"Map: 100%"}},"c7f1596aee54403680a00c37fb009681":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef7710287ec44b90ba31f22a1faa04f1","max":20000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ca2e2cba5f3d48b7a03bf6311be41fad","value":20000}},"b26b31daee2349e58dd7d4b80345e528":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d5a19f86b9f462283d8af6cff99db74","placeholder":"​","style":"IPY_MODEL_5fee996710b1436c83722bc3ce3b2884","value":" 20000/20000 [00:01&lt;00:00, 14839.25 examples/s]"}},"8ac084fcfaeb433ea59ec1647ab580b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8b90e2fdaa9489dad98e78e3f9ff79a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8fa18a97ef8c411a828c629e2c9795a7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ef7710287ec44b90ba31f22a1faa04f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ca2e2cba5f3d48b7a03bf6311be41fad":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6d5a19f86b9f462283d8af6cff99db74":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5fee996710b1436c83722bc3ce3b2884":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"be138f6f","cell_type":"markdown","source":"# Knowdge Distillation using Contrastive Learning\n","metadata":{"id":"be138f6f","papermill":{"duration":0.02181,"end_time":"2024-12-18T17:13:30.324107","exception":false,"start_time":"2024-12-18T17:13:30.302297","status":"completed"},"tags":[]}},{"id":"376ecc79","cell_type":"markdown","source":" #### Student Name: Farzan Rahmani\n\n\n #### Student ID: 403210725\n","metadata":{"id":"376ecc79","papermill":{"duration":0.014958,"end_time":"2024-12-18T17:13:30.355437","exception":false,"start_time":"2024-12-18T17:13:30.340479","status":"completed"},"tags":[]}},{"id":"a1dba4d2","cell_type":"markdown","source":"In this exercise, we aim to distill knowledge from a large monolingual model into a smaller multilingual model using contrastive learning, specifically leveraging the CLIP model loss.\n\nWe employ a small paired English-Persian dataset to define the loss pairs for our CLIP training. Given the substantial dataset size and batch size typically required for CLIP's loss computation (exceeding 19,000 samples per batch in standard tasks), which is impractical for our setup on Colab, we use a reduced batch size to focus on learning the procedure rather than achieving optimal performance, so we don't expect actual real-world results, only the training prcodure.","metadata":{"id":"a1dba4d2","papermill":{"duration":0.014965,"end_time":"2024-12-18T17:13:30.385132","exception":false,"start_time":"2024-12-18T17:13:30.370167","status":"completed"},"tags":[]}},{"id":"90e95f9e","cell_type":"markdown","source":"CLIP (Contrastive Language-Image Pretraining) is a foundational model introduced by OpenAI to bridge the gap between text and image modalities. By aligning text descriptions and corresponding images in a shared embedding space, CLIP achieves remarkable zero-shot generalization capabilities across a wide range of tasks. It is trained on a massive dataset of image-text pairs using contrastive loss, ensuring that image embeddings align closely with their corresponding textual descriptions while remaining distinct from unrelated samples. This cross-modal alignment enables CLIP to perform tasks like image retrieval, captioning, and classification with minimal fine-tuning.\n\nThe CLIP loss plays a crucial role in training the model by implementing a cross-entropy loss function in the contrastive learning framework. This loss operates on paired data, where each image-text pair is treated as a positive match, while all other pair combinations in the batch are considered negatives. The loss ensures that positive pairs receive high similarity scores, while negatives are penalized. However, achieving optimal results with CLIP loss often requires large batch sizes to provide sufficient negative samples, which can be computationally intensive. This makes training with limited resources challenging, necessitating adaptations such as smaller batch sizes or alternative strategies to approximate the training dynamics.\n\n\nKnowledge distillation is a technique used in machine learning to transfer knowledge from a large, complex model (the \"teacher\") to a smaller, more efficient model (the \"student\"). The primary goal of this process is to retain the performance and accuracy of the larger model while significantly reducing computational and memory requirements. This is achieved by training the student model to mimic the outputs of the teacher model, often through techniques such as matching soft probability distributions or intermediate representations. Knowledge distillation has become an essential approach in deploying machine learning models on resource-constrained devices such as smartphones and edge devices.\n\nIn practice, knowledge distillation is not limited to replicating predictions; it can also involve transferring knowledge about internal features or learned representations.\n\n\n### Challenges in Resource-Constrained Settings\nCLIP’s reliance on large-scale datasets and batch sizes makes direct implementation computationally demanding. This exercise demonstrates an adaptation of the process, reducing batch size and dataset size to provide a practical understanding of the training procedure. While this approach sacrifices performance and real-world applicability, it highlights the mechanics of using CLIP loss for contrastive learning and lays the foundation for extending the process to larger datasets and batch sizes in future applications.\n\n\n\n### About CLIP and Contrastive Learning\nCLIP, developed by OpenAI, bridges the gap between text and image modalities by aligning corresponding embeddings in a shared space. It leverages contrastive loss to train on image-text pairs, ensuring that embeddings of positive pairs (e.g., an image and its corresponding caption) are highly similar, while embeddings of unrelated pairs remain distinct. The cross-entropy-based contrastive loss evaluates the similarity between positive pairs while penalizing mismatches for all other combinations within a batch.\n\n### Key aspects of CLIP loss include:\n\n- Positive Pairing: Encourages high similarity scores for embeddings of paired text and image data.\n- Negative Sampling: Penalizes mismatched pairs within the batch, requiring large batch sizes for effective performance due to the need for a diverse set of negative samples.\n\n","metadata":{"id":"90e95f9e","papermill":{"duration":0.014841,"end_time":"2024-12-18T17:13:30.414686","exception":false,"start_time":"2024-12-18T17:13:30.399845","status":"completed"},"tags":[]}},{"id":"ba7c7274","cell_type":"markdown","source":"## !!! Note !!! You Should Answer to all the TODOs\n\nAlso feel free to ask your questions on Quera.","metadata":{"id":"ba7c7274","papermill":{"duration":0.01457,"end_time":"2024-12-18T17:13:30.444777","exception":false,"start_time":"2024-12-18T17:13:30.430207","status":"completed"},"tags":[]}},{"id":"e7da461e","cell_type":"markdown","source":"\n\n## Setup\n","metadata":{"id":"e7da461e","papermill":{"duration":0.014905,"end_time":"2024-12-18T17:13:30.474341","exception":false,"start_time":"2024-12-18T17:13:30.459436","status":"completed"},"tags":[]}},{"id":"06e48967","cell_type":"markdown","source":"We install Required Packages.","metadata":{"id":"06e48967","papermill":{"duration":0.014958,"end_time":"2024-12-18T17:13:30.503840","exception":false,"start_time":"2024-12-18T17:13:30.488882","status":"completed"},"tags":[]}},{"id":"69339c7a","cell_type":"code","source":"!pip install -q gdown\n!gdown \"https://drive.google.com/uc?id=1MVx_gIkX4tQ8ya2OsHt0mqLmw1Pf2CcK\"\n!gdown \"https://drive.google.com/uc?id=1Co-dwJfWw-C_ral0hoAS_X94wN-_vbCj\"","metadata":{"execution":{"iopub.status.busy":"2025-01-15T15:17:04.528657Z","iopub.execute_input":"2025-01-15T15:17:04.528865Z","iopub.status.idle":"2025-01-15T15:17:18.348719Z","shell.execute_reply.started":"2025-01-15T15:17:04.528845Z","shell.execute_reply":"2025-01-15T15:17:18.347459Z"},"id":"69339c7a","outputId":"82320f1f-8e73-4816-be6a-5f47a2a72bb8","papermill":{"duration":20.264414,"end_time":"2024-12-18T17:13:50.783672","exception":false,"start_time":"2024-12-18T17:13:30.519258","status":"completed"},"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"trusted":true},"outputs":[{"name":"stdout","text":"Downloading...\nFrom: https://drive.google.com/uc?id=1MVx_gIkX4tQ8ya2OsHt0mqLmw1Pf2CcK\nTo: /kaggle/working/train.csv\n100%|███████████████████████████████████████| 7.35M/7.35M [00:00<00:00, 191MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1Co-dwJfWw-C_ral0hoAS_X94wN-_vbCj\nTo: /kaggle/working/val.csv\n100%|███████████████████████████████████████| 2.45M/2.45M [00:00<00:00, 157MB/s]\n","output_type":"stream"}],"execution_count":1},{"id":"cS5i-1Xev2kn","cell_type":"code","source":"%ls","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cS5i-1Xev2kn","outputId":"0189fbb6-0a8e-4e01-fcc0-0ce27b07699a","trusted":true,"execution":{"iopub.status.busy":"2025-01-15T15:17:18.350597Z","iopub.execute_input":"2025-01-15T15:17:18.350918Z","iopub.status.idle":"2025-01-15T15:17:18.471677Z","shell.execute_reply.started":"2025-01-15T15:17:18.350894Z","shell.execute_reply":"2025-01-15T15:17:18.470603Z"}},"outputs":[{"name":"stdout","text":"train.csv  val.csv\n","output_type":"stream"}],"execution_count":2},{"id":"70d93c5e","cell_type":"code","source":"!pip install setuptools\nimport sys\nimport subprocess\nimport pkg_resources\n\ndef installPackages(packages):\n    def installPackage(package):\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n\n    for package in REQUIRED_PACKAGES:\n        try:\n            dist = pkg_resources.get_distribution(package)\n            print('{} ({}) is installed'.format(dist.key, dist.version))\n        except pkg_resources.DistributionNotFound:\n            print('{} is NOT installed'.format(package))\n            installPackage(package)\n            print('{} was successfully installed.'.format(package))\n\nREQUIRED_PACKAGES = [\n    'open_clip-torch',\n    'pandas',\n    'numpy',\n    'matplotlib',\n    'transformers',\n    'tqdm',\n    'torch',\n    'datasets',\n]\n\ninstallPackages(REQUIRED_PACKAGES)\n\nimport gc\nimport itertools\nimport re\nimport math\nfrom collections import Counter\nimport random\nimport string\nimport uuid\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport open_clip\nfrom open_clip import model as TE\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\n\nfrom datasets import load_dataset, Dataset, Features, Array2D, Value\nfrom transformers import AutoConfig, AutoTokenizer, AutoModel, TFAutoModel\n\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2025-01-15T15:17:18.473125Z","iopub.execute_input":"2025-01-15T15:17:18.473503Z","iopub.status.idle":"2025-01-15T15:17:41.031904Z","shell.execute_reply.started":"2025-01-15T15:17:18.473453Z","shell.execute_reply":"2025-01-15T15:17:41.031144Z"},"id":"70d93c5e","outputId":"eb8c90ae-dfb6-47cc-ae05-590e21f7f91d","papermill":{"duration":24.516699,"end_time":"2024-12-18T17:14:15.316512","exception":false,"start_time":"2024-12-18T17:13:50.799813","status":"completed"},"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"trusted":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (75.1.0)\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-3-16d6a20cb021>:4: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n  import pkg_resources\n","output_type":"stream"},{"name":"stdout","text":"open_clip-torch is NOT installed\nopen_clip-torch was successfully installed.\npandas (2.2.2) is installed\nnumpy (1.26.4) is installed\nmatplotlib (3.7.5) is installed\ntransformers (4.47.0) is installed\ntqdm (4.67.1) is installed\ntorch (2.5.1+cu121) is installed\ndatasets (3.2.0) is installed\n","output_type":"stream"}],"execution_count":3},{"id":"f4c39c86","cell_type":"markdown","source":"Beware to use cuda for training!","metadata":{"id":"f4c39c86","papermill":{"duration":0.01563,"end_time":"2024-12-18T17:14:15.349709","exception":false,"start_time":"2024-12-18T17:14:15.334079","status":"completed"},"tags":[]}},{"id":"fd519039","cell_type":"code","source":"def getDevice(which=\"cuda:0\", yellAtCpu=True):\n    if torch.cuda.is_available():\n        device = torch.device(which)\n    else:\n        if yellAtCpu:\n             raise Exception(\"I won't run on CPU!\")\n        device = torch.device(\"cpu\")\n\n    return device","metadata":{"execution":{"iopub.status.busy":"2025-01-15T15:17:41.032790Z","iopub.execute_input":"2025-01-15T15:17:41.033405Z","iopub.status.idle":"2025-01-15T15:17:41.038007Z","shell.execute_reply.started":"2025-01-15T15:17:41.033376Z","shell.execute_reply":"2025-01-15T15:17:41.036989Z"},"id":"fd519039","papermill":{"duration":0.024557,"end_time":"2024-12-18T17:14:15.389794","exception":false,"start_time":"2024-12-18T17:14:15.365237","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":4},{"id":"67a2eff9","cell_type":"markdown","source":"#### Configs","metadata":{"id":"67a2eff9","papermill":{"duration":0.016217,"end_time":"2024-12-18T17:14:15.422727","exception":false,"start_time":"2024-12-18T17:14:15.406510","status":"completed"},"tags":[]}},{"id":"75c787a8","cell_type":"markdown","source":"These are our training configurations, read them!","metadata":{"id":"75c787a8","papermill":{"duration":0.016978,"end_time":"2024-12-18T17:14:15.455652","exception":false,"start_time":"2024-12-18T17:14:15.438674","status":"completed"},"tags":[]}},{"id":"802d832e","cell_type":"code","source":"def Configs():\n    return {\n        \"device\": getDevice(),\n        \"reference_checkPoint\" : \"EVA02-E-14-plus\",                # teacher\n        \"candidate_checkpoint\" : \"setu4993/smaller-LaBSE\",         # student\n        \"train_path\" : \"train.csv\",\n        \"val_path\" : \"val.csv\",\n        \"save_path\" : \"./best-model.pth\",\n        \"english\" : \"en\",                                         # dont mind them\n        \"persian\" : \"fa\",\n        \"batch_size\": 128,                                        # should have been really big, but we can't here\n        \"lr\": 1e-4,\n        \"epochs\": 5,                                               # 40 minute per epoch\n        \"tok_percentile\" : 99, # Read the whole code and find out what tok_percentile is used for!\n        \"temperature\": 20,\n        \"dropout\": 0.05,\n        \"unfreezed_layers\" : 10,\n        \"weight_decay\": 1e-5,\n        \"patience\": 1,\n        \"factor\" : 0.8,\n        \"reference_embedding\": 1024,                               # DONT MIND THESE\n        \"reference_context_length\" : 77,\n        \"reference_vocab_size\" : 49408,\n        \"reference_heads\" : 20,\n        \"reference_width\" : 1280,\n        \"reference_layers\" : 32,\n        \"cls_token_index\" : 0,\n        \"project_to\" : 1024,\n    }\n\nconfigs = Configs()","metadata":{"execution":{"iopub.status.busy":"2025-01-15T15:17:41.040839Z","iopub.execute_input":"2025-01-15T15:17:41.041141Z","iopub.status.idle":"2025-01-15T15:17:41.121618Z","shell.execute_reply.started":"2025-01-15T15:17:41.041119Z","shell.execute_reply":"2025-01-15T15:17:41.120680Z"},"id":"802d832e","papermill":{"duration":0.11541,"end_time":"2024-12-18T17:14:15.591685","exception":false,"start_time":"2024-12-18T17:14:15.476275","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":5},{"id":"7b95e360","cell_type":"markdown","source":"## Question Box\n### TODO (10pts)\n1- Why do we use temperature in training using contrastive learning?\n\nTemperature in contrastive learning serves multiple important purposes:\n- It controls the \"sharpness\" of the similarity distribution between embeddings\n- Higher temperature makes the distribution more uniform, while lower temperature makes it more peaked\n- It helps calibrate the model's confidence and prevents the model from becoming overconfident\n- It can help avoid collapsed representations where all samples are mapped to the same point\n- Acts as a scaling factor that can help with numerical stability during training\n\nIn other words, Temperature is used in contrastive learning to control the sharpness of the similarity scores (logits) between embeddings. A higher temperature makes the logits smoother, allowing the model to focus on learning from a broader range of similarities, while a lower temperature makes the logits sharper, emphasizing the most confident predictions. This helps in balancing the exploration and exploitation of the model during training. Furthermore, This scaling helps in improving the convergence of the contrastive loss by adjusting the similarity scores between embeddings.\n\n<br/>\n\n2- Why do we need to freeze some layers of a model? mention 2 reasons.\n\n- To prevent overfitting when we have limited training data, as fewer trainable parameters means less risk of overfitting\n- To reduce computational resources, computational cost and training time, as we don't need to compute gradients and update parameters for frozen layers\n- To preserve the knowledge learned in the pre-trained layers while fine-tuning only the task-specific layers\n- To implement transfer learning effectively by keeping the feature extraction layers fixed. In fact, Freezing layers allows us to retain the knowledge learned from a pre-trained model while fine-tuning only the top layers for a specific task.\n\n<br/>\n\n3- Read the whole code and find out what tok_percentile is used for.\n\nThe tok_percentile parameter is used in the calcPrcentileTokens function to determine the maximum sequence length for tokenization. It calculates the token length at a specific percentile (99th percentile in this case) across the dataset to set an appropriate max_length for padding/truncation. This helps handle variable-length inputs efficiently while covering most of the data. In other words, tok_percentile is used to determine the maximum token length for padding/truncation based on the token length distribution in the dataset. It ensures that the majority of the sentences are not truncated, reducing information loss.","metadata":{"id":"7b95e360","papermill":{"duration":0.015595,"end_time":"2024-12-18T17:14:15.623791","exception":false,"start_time":"2024-12-18T17:14:15.608196","status":"completed"},"tags":[]}},{"id":"6a9cfd8b","cell_type":"markdown","source":"## Data and Preprocessing","metadata":{"id":"6a9cfd8b","papermill":{"duration":0.015679,"end_time":"2024-12-18T17:14:15.655199","exception":false,"start_time":"2024-12-18T17:14:15.639520","status":"completed"},"tags":[]}},{"id":"5d84bc5a","cell_type":"code","source":"def getDatasetsCSV(prevEnCol, prevFaCol, newEnCol, newFaCol, trainPath, valPath):\n    df = pd.read_csv(trainPath)\n    dfVal = pd.read_csv(valPath)\n\n    if df.empty:\n        raise ValueError(\"Training dataset is empty or missing\")\n\n    if dfVal.empty:\n        raise ValueError(\"Validation dataset is empty or missing\")\n\n    dfTraind = df.loc[:, [prevEnCol, prevFaCol]].rename(columns={prevEnCol: newEnCol, prevFaCol: newFaCol})\n    dfVal = dfVal.loc[:, [prevEnCol, prevFaCol]].rename(columns={prevEnCol: newEnCol, prevFaCol: newFaCol})\n\n    datasetTrain = Dataset.from_pandas(dfTraind)\n    datasetVal = Dataset.from_pandas(dfVal)\n\n    return datasetTrain, datasetVal\n\ndef getDsByLang(persianCol, englishCol):\n    def getPersianDs(dataset):\n        return dataset[persianCol]\n\n    def getEnglishDs(dataset):\n        return dataset[englishCol]\n\n    getPersianDs.label = persianCol\n    getEnglishDs.label = englishCol\n\n    return getPersianDs, getEnglishDs\n\nclass Normalizer():\n    def __init__(self):\n        translation_src = ' ىكي“”0123456789%إأآئيؤةك'\n        translation_dst = ' یکی\"\"۰۱۲۳۴۵۶۷۸۹٪اااییوهک'\n\n        self.translations = str.maketrans(translation_src, translation_dst)\n\n        patterns = [\n            (r' {2,}', ' '),  # remove extra spaces\n            (r'\\n+', ' '),  # replace newlines with space\n            (r'\\u200c+', ' '),  # replace ZWNJs with space\n            (r'[ـ\\r]', '')  # remove keshide, carriage returns\n        ]\n\n        self.character_refinement_patterns = [(re.compile(pattern), repl) for pattern, repl in patterns]\n\n    def normalizeFa(self, text):\n        text = text.lower().translate(self.translations)\n        text = re.sub('[^a-zA-Z۰-۹آ-ی ]', ' ', text)\n\n        for pattern, repl in self.character_refinement_patterns:\n            text = pattern.sub(repl, text)\n        return text.strip()\n\n    def normalizeEn(self, text):\n        text = text.lower()\n        text = text.translate(str.maketrans('', '', string.punctuation)) # Remove punctuation\n        return text\n\ndef applyPreprocess(datasets, configs=configs, Normalizer=Normalizer):\n    def applyRowNormalization(example):\n        example[configs['persian']] = normalizer.normalizeFa(example[configs['persian']])\n        example[configs['english']] = normalizer.normalizeEn(example[configs['english']])\n\n        return example\n\n    normalizer = Normalizer()\n\n    newDatasets = []\n    for dataset in datasets:\n        newDatasets.append(dataset.map(applyRowNormalization))\n\n    return newDatasets\n\ndef preprocessSentence(text, lang, mostFreq=None, Normalizer=Normalizer, configs=configs):\n    normalizer = Normalizer()\n    if lang == configs['persian']:\n        normalized = normalizer.normalizeFa(text)\n    elif lang == configs['english']:\n        normalized = normalizer.normalizeEn(text)\n    else:\n        raise ValueError(\"Not supported lang\")\n\n    return normalized","metadata":{"execution":{"iopub.status.busy":"2025-01-15T15:17:41.123137Z","iopub.execute_input":"2025-01-15T15:17:41.123523Z","iopub.status.idle":"2025-01-15T15:17:41.143483Z","shell.execute_reply.started":"2025-01-15T15:17:41.123498Z","shell.execute_reply":"2025-01-15T15:17:41.142581Z"},"id":"5d84bc5a","papermill":{"duration":0.031369,"end_time":"2024-12-18T17:14:15.702439","exception":false,"start_time":"2024-12-18T17:14:15.671070","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":6},{"id":"86190e87","cell_type":"markdown","source":"## Utils\n### TODO: Complete these Utility functions (10pts)","metadata":{"id":"86190e87","papermill":{"duration":0.016557,"end_time":"2024-12-18T17:14:15.735930","exception":false,"start_time":"2024-12-18T17:14:15.719373","status":"completed"},"tags":[]}},{"id":"7b0c992a","cell_type":"code","source":"def getClsToken(tensor, configs=configs):\n    \"\"\"\n    Extracts the classification (CLS) token from the input tensor.\n\n    Parameters:\n        tensor (torch.Tensor): The input tensor of shape (batch_size, seq_length, hidden_dim).\n        configs (dict): A dictionary containing configuration settings. Must include the key \"cls_token_index\"\n                        which specifies the index of the CLS token in the sequence dimension.\n\n    Returns:\n        torch.Tensor: A tensor containing the CLS token for each example in the batch,\n                      of shape (batch_size, 1, hidden_dim).\n    \"\"\"\n    clsId = configs[\"cls_token_index\"]\n    #TODO\n    return tensor[:, clsId, :].unsqueeze(1)\n\ndef flattenMiddle(tensor):\n    \"\"\"\n    Flattens the middle dimension (sequence length) of the input tensor, removing it.\n\n    Parameters:\n        tensor (torch.Tensor): The input tensor of shape (batch_size, seq_length, hidden_dim).\n\n    Returns:\n        torch.Tensor: A tensor of shape (batch_size, hidden_dim) with the middle dimension flattened out.\n    \"\"\"\n    #TODO\n    return tensor.squeeze(1)\n\ndef freezeModel(model):\n    \"\"\"\n    Freeze all parameters of a given model.\n    Parameters:\n        model (torch.nn.Module): The PyTorch model whose parameters are to be frozen.\n    \"\"\"\n    #TODO\n    for param in model.parameters():\n        param.requires_grad = False\n    return model","metadata":{"execution":{"iopub.status.busy":"2025-01-15T15:17:41.144270Z","iopub.execute_input":"2025-01-15T15:17:41.144540Z","iopub.status.idle":"2025-01-15T15:17:41.166136Z","shell.execute_reply.started":"2025-01-15T15:17:41.144518Z","shell.execute_reply":"2025-01-15T15:17:41.165273Z"},"id":"7b0c992a","papermill":{"duration":0.025354,"end_time":"2024-12-18T17:14:15.778667","exception":false,"start_time":"2024-12-18T17:14:15.753313","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":7},{"id":"2489bf4f","cell_type":"code","source":"def plotMetric(metricData, metricName):\n    if metricName == None or metricName not in metricData:\n        raise ValueError(\"No such metric\")\n    metricData[metricName].plot()\n    plt.xlabel('Epochs')\n    plt.ylabel(metricName)\n    plt.title(f'Plot of {metricName}')\n    plt.show()\n\nthreshold=1\ndef calcPrcentileTokens(dataset, tokenizer, field, percentile=configs[\"tok_percentile\"], thershold=1):\n    \"\"\"\n    Calculate the token length at a specific percentile for a dataset field.\n\n    This function tokenizes the data in the specified field of the dataset and calculates\n    the token length at the given percentile. An optional threshold can be added to the result.\n\n    Parameters:\n        dataset (dict or Dataset): The dataset containing the data to be tokenized.\n        tokenizer (callable): A tokenizer function or object with a callable interface\n                              (e.g., HuggingFace tokenizer).\n        field (str): The field in the dataset whose token lengths are to be calculated.\n        percentile (float, optional): The percentile to compute (default is the value in\n                                       `configs[\"tok_percentile\"]`).\n        thershold (int, optional): A value to add to the calculated percentile token length\n                                    (default is 1).\n\n    Returns:\n        int: The token length at the specified percentile plus the threshold.\n\n    Raises:\n        KeyError: If the specified field does not exist in the dataset.\n        TypeError: If `tokenized` is not in the expected format.\n\n    Example:\n        dataset = {\"text\": [\"This is a sentence.\", \"Another example sentence.\"]}\n        tokenizer = lambda x: {\"input_ids\": [[1, 2, 3, 4], [5, 6, 7, 8, 9]]}\n        field = \"text\"\n        calcPrcentileTokens(dataset, tokenizer, field, percentile=95, thershold=2)\n\n    Notes:\n        - If the tokenized output is a dictionary (e.g., HuggingFace tokenizers), it assumes\n          that `input_ids` contains the token sequences.\n        - If the tokenized output is a tensor, nonzero token counts are used to determine lengths.\n    \"\"\"\n    tokenized = tokenizer(dataset[field])\n    if not isinstance(tokenized, torch.Tensor):\n        tokenLengths = list(map(lambda sen: len(sen), tokenized['input_ids']))\n    else:\n        tokenLengths = [tensor.nonzero().size(0) for tensor in tokenized]\n    percentileLength = np.percentile(tokenLengths, percentile)\n    return int(percentileLength) + 1\n\n# Dont Touch This\ndef TextEncoder(configs):\n    newModel = TE.TextTransformer(context_length=configs['reference_context_length'],\n                                 vocab_size=configs[\"reference_vocab_size\"],\n                                 width=configs[\"reference_width\"],\n                                 layers=configs[\"reference_layers\"],\n                                 heads=configs[\"reference_heads\"],\n                                 output_dim=configs[\"reference_embedding\"])\n    return newModel","metadata":{"execution":{"iopub.status.busy":"2025-01-15T15:17:41.167362Z","iopub.execute_input":"2025-01-15T15:17:41.167708Z","iopub.status.idle":"2025-01-15T15:17:41.185229Z","shell.execute_reply.started":"2025-01-15T15:17:41.167678Z","shell.execute_reply":"2025-01-15T15:17:41.183943Z"},"id":"2489bf4f","papermill":{"duration":0.026945,"end_time":"2024-12-18T17:14:15.822548","exception":false,"start_time":"2024-12-18T17:14:15.795603","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":8},{"id":"ee90637f","cell_type":"markdown","source":"## Models","metadata":{"id":"ee90637f","papermill":{"duration":0.016248,"end_time":"2024-12-18T17:14:15.854449","exception":false,"start_time":"2024-12-18T17:14:15.838201","status":"completed"},"tags":[]}},{"id":"7f75d675","cell_type":"markdown","source":"### TODO: Compelete the Swish and LinearProjection functions based on the pydoc provided (15pts)","metadata":{"id":"7f75d675","papermill":{"duration":0.016386,"end_time":"2024-12-18T17:14:15.886639","exception":false,"start_time":"2024-12-18T17:14:15.870253","status":"completed"},"tags":[]}},{"id":"83acbdd5","cell_type":"code","source":"class Swish(nn.Module):\n    \"\"\"\n    Implements the Swish activation function.\n    Parameters:\n        beta (float, optional): The scaling parameter for the input x in the sigmoid\n                                function. Default is 1.0.\n    \"\"\"\n    def __init__(self, beta=1.0):\n        super().__init__()\n        self.beta = beta\n\n    def forward(self, x):\n        #TODO\n        return x * torch.sigmoid(self.beta * x)\n\n\nclass LinearProjection(nn.Module):\n    \"\"\"\n    A projection layer with Swish activation, batch normalization, dropout, and residual connections.\n\n    This module takes an input tensor, applies a series of transformations, and produces an\n    output tensor of the same shape, making use of residual connections and layer normalization.\n\n    Parameters:\n        embedding_dim (int): The dimensionality of the input embeddings.\n        projection_dim (int, optional): The dimensionality of the projection. Default is\n                                        `configs['project_to']`.\n        dropout (float, optional): The dropout rate. Default is `configs['dropout']`.\n\n    Layers:\n        - projection: Linear layer that projects the input to the specified `projection_dim`.\n        - swish: Swish activation function with a fixed beta of 1.0.\n        - batch_norm: Batch normalization applied after projection.\n        - fc: Fully connected layer for further transformations.\n        - dropout: Dropout applied to the output of the fully connected layer.\n        - layer_norm: Layer normalization applied after residual connection.\n\n    Methods:\n        forward(x):\n            Applies the projection, activation, normalization, dropout, residual connection,\n            and layer normalization to the input tensor.\n\n    Example:\n        model = LinearProjection(embedding_dim=128, projection_dim=64, dropout=0.1)\n        output = model(input_tensor)\n    \"\"\"\n    def __init__(self, embedding_dim, projection_dim=configs['project_to'], dropout=configs['dropout']):\n        super(LinearProjection, self).__init__()\n        #TODO\n        # First project to the target dimension (projection_dim)\n        self.initial_projection = nn.Linear(embedding_dim, projection_dim) # because of shape error\n        # The rest of the layers will work with target dimension (projection_dim)\n        self.projection = nn.Linear(projection_dim, projection_dim)\n        self.swish = Swish(beta=1.0)\n        self.batch_norm = nn.BatchNorm1d(projection_dim)\n        self.fc = nn.Linear(projection_dim, projection_dim)\n        self.dropout = nn.Dropout(dropout)\n        self.layer_norm = nn.LayerNorm(projection_dim)\n\n    def forward(self, x):\n        #TODO\n        # First project input x to target dimension (projection_dim)\n        x = self.initial_projection(x)\n        # Now apply the residual block to projected input\n        residual = x\n        x = self.projection(x)\n        x = self.swish(x)\n        x = self.batch_norm(x)\n        x = self.fc(x)\n        x = self.dropout(x)\n        x = x + residual\n        x = self.layer_norm(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2025-01-15T15:17:41.186377Z","iopub.execute_input":"2025-01-15T15:17:41.186746Z","iopub.status.idle":"2025-01-15T15:17:41.204449Z","shell.execute_reply.started":"2025-01-15T15:17:41.186712Z","shell.execute_reply":"2025-01-15T15:17:41.203580Z"},"id":"83acbdd5","papermill":{"duration":0.02619,"end_time":"2024-12-18T17:14:15.929057","exception":false,"start_time":"2024-12-18T17:14:15.902867","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":9},{"id":"ece3abb5","cell_type":"code","source":"class CandidateModel(nn.Module):\n    def __init__(self, model_name, unfreezeLayers, trainable=True):\n        super().__init__()\n        self.candidateProjection = LinearProjection(embedding_dim=configs[\"candidate_embedding\"])\n        self.configs = AutoConfig.from_pretrained(model_name)\n        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n        self.model = AutoModel.from_pretrained(model_name)\n        self.batchNorm = nn.BatchNorm1d(1, configs[\"candidate_embedding\"])\n        self.targetTokenIdx = configs[\"cls_token_index\"]\n\n    def forward(self, input_ids, attention_mask):\n        output = self.model(input_ids=input_ids, attention_mask=attention_mask)\n        clsEmbed = getClsToken(output.last_hidden_state)\n        clsEmbed = self.batchNorm(clsEmbed)\n        clsEmbed = self.candidateProjection(flattenMiddle(clsEmbed))\n        return clsEmbed","metadata":{"execution":{"iopub.status.busy":"2025-01-15T15:17:41.205260Z","iopub.execute_input":"2025-01-15T15:17:41.205527Z","iopub.status.idle":"2025-01-15T15:17:41.218658Z","shell.execute_reply.started":"2025-01-15T15:17:41.205506Z","shell.execute_reply":"2025-01-15T15:17:41.217936Z"},"id":"ece3abb5","papermill":{"duration":0.024135,"end_time":"2024-12-18T17:14:15.969481","exception":false,"start_time":"2024-12-18T17:14:15.945346","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":10},{"id":"4e0dd33e","cell_type":"markdown","source":"## Training","metadata":{"id":"4e0dd33e","papermill":{"duration":0.015974,"end_time":"2024-12-18T17:14:16.001750","exception":false,"start_time":"2024-12-18T17:14:15.985776","status":"completed"},"tags":[]}},{"id":"92d73eeb","cell_type":"markdown","source":"### TODO: Compelete the calcLoss functions based on the pydoc provided (20pts)","metadata":{"id":"92d73eeb","papermill":{"duration":0.015543,"end_time":"2024-12-18T17:14:16.033408","exception":false,"start_time":"2024-12-18T17:14:16.017865","status":"completed"},"tags":[]}},{"id":"c8e57071","cell_type":"code","source":"def calcLoss(batch, referenceModel, candidateModel, temperature):\n    \"\"\"\n    Compute the loss and the number of correct predictions for a contrastive learning task.\n\n    This function calculates a symmetric cross-entropy loss between the embeddings\n    generated by a reference model and a candidate model. It also computes the\n    number of correct predictions based on the alignment of the embeddings.\n\n    Args:\n        batch (dict): A batch of data containing:\n            - \"candidate\" (torch.Tensor): Tokenized input for the candidate model.\n            - \"reference\" (torch.Tensor): Tokenized input for the reference model.\n        referenceModel (nn.Module): The model generating embeddings for the reference input.\n        candidateModel (nn.Module): The model generating embeddings for the candidate input.\n        temperature (float): A scaling factor to control the logits' sharpness during similarity calculation.\n\n    Returns:\n        tuple:\n            - loss (torch.Tensor): The computed symmetric cross-entropy loss.\n            - corrects (int): The number of correctly predicted alignments.\n\n    Notes:\n        - The embeddings are normalized to ensure their magnitudes do not impact similarity.\n        - Logits represent scaled cosine similarity between reference and candidate embeddings.\n        - The targets are identity matrices, assuming perfect alignment between reference and candidate inputs.\n\n    Example Usage:\n        batch = {\n            \"candidate\": tokenized_candidate,\n            \"reference\": tokenized_reference\n        }\n        loss, corrects = calcLoss(batch, reference_model, candidate_model, temperature=0.1)\n    \"\"\"\n    # Move tokenized inputs to the specified device\n    candidateTokenized = batch[\"candidate\"].to(configs[\"device\"])\n    referenceTokenized = batch[\"reference\"].to(configs[\"device\"])\n\n    # Generate embeddings from reference and candidate models\n    referenceEmbeds = referenceModel(referenceTokenized)\n    candidateEmbeds = candidateModel(\n        input_ids=candidateTokenized[\"input_ids\"],\n        attention_mask=candidateTokenized[\"attention_mask\"]\n    )\n\n    # Normalize embeddings to have unit length\n    referenceEmbeds = F.normalize(referenceEmbeds, p=2, dim=-1)\n    candidateEmbeds = F.normalize(candidateEmbeds, p=2, dim=-1)\n\n    #TODO\n    logits = torch.matmul(candidateEmbeds, referenceEmbeds.t()) * temperature\n    targets = torch.arange(logits.size(0)).to(configs[\"device\"])\n    loss = (F.cross_entropy(logits, targets) + F.cross_entropy(logits.T, targets)) / 2\n    corrects = (logits.argmax(dim=1) == targets).sum().item()\n\n    return loss, corrects","metadata":{"execution":{"iopub.status.busy":"2025-01-15T15:17:41.219424Z","iopub.execute_input":"2025-01-15T15:17:41.219680Z","iopub.status.idle":"2025-01-15T15:17:41.231566Z","shell.execute_reply.started":"2025-01-15T15:17:41.219660Z","shell.execute_reply":"2025-01-15T15:17:41.230813Z"},"id":"c8e57071","papermill":{"duration":0.024464,"end_time":"2024-12-18T17:14:16.074093","exception":false,"start_time":"2024-12-18T17:14:16.049629","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":11},{"id":"5f1b4edc","cell_type":"markdown","source":"### TODO: Fill the trainLoop and valLoop (5pts)","metadata":{"id":"5f1b4edc","papermill":{"duration":0.015457,"end_time":"2024-12-18T17:14:16.105022","exception":false,"start_time":"2024-12-18T17:14:16.089565","status":"completed"},"tags":[]}},{"id":"05f0bf97","cell_type":"code","source":"def trainLoop(dataloader, models, referenceTokenizer, candidateTokenizer, optimizer, temperature):\n    models['candidateModel'].train()\n\n    totalLoss = 0.0\n    totalCorrects = 0\n\n    print(\"Training Starts!\")\n    for (index, pairs) in tqdm(enumerate(dataloader), total=len(dataloader)):\n\n        candidteTokenized = candidateTokenizer(getPersianDs(pairs), padding='max_length', truncation=True, return_tensors=\"pt\", max_length=configs[\"fa_tok_percentile\"])\n        referenceTextTokenized = referenceTokenizer(getEnglishDs(pairs))\n\n        batch = {\n            \"candidate\" : candidteTokenized,\n            \"reference\" : referenceTextTokenized\n        }\n\n        loss, corrects = calcLoss(batch, models['referenceModel'], models['candidateModel'], temperature)\n        # totalCorrects += #TODO\n        # totalLoss += #TODO\n        # #TODO\n        # #TODO\n        # #TODO\n        \n        totalCorrects += corrects\n        totalLoss += loss.item()\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n    avgLoss = totalLoss / len(dataloader.dataset)\n    avgAccuracy = totalCorrects / len(dataloader.dataset)\n\n    # print(\"train loss\", avgLoss.to(\"cpu\").item()) # .to(\"cpu\") error because float object has no attribute error .to\n    print(\"train loss\", avgLoss)  # avgLoss is already a float, No need for .to(\"cpu\").item() \n    print(\"train accuracy\", avgAccuracy)\n\n    return avgLoss, avgAccuracy\n\ndef valLoop(dataloader, models, referenceTokenizer, candidateTokenizer, temperature):\n    models['candidateModel'].eval()\n\n    print(\"Testing Starts!\")\n    totalLoss = 0.0\n    totalCorrects = 0\n\n    with torch.no_grad():\n        for (index, pairs) in tqdm(enumerate(dataloader), total=len(dataloader)):\n            candidteTokenized = candidateTokenizer(getPersianDs(pairs), padding='max_length', truncation=True, return_tensors=\"pt\", max_length=configs[\"fa_tok_percentile\"])\n            referenceTextTokenized = referenceTokenizer(getEnglishDs(pairs))\n\n            batch = {\n                \"candidate\" : candidteTokenized,\n                \"reference\" : referenceTextTokenized\n            }\n\n            loss, corrects = calcLoss(batch, models['referenceModel'], models['candidateModel'], temperature)\n\n            # totalCorrects += #TODO\n            # totalLoss += #TODO\n            totalCorrects += corrects\n            totalLoss += loss.item()\n\n    avgLoss = totalLoss / len(dataloader.dataset)\n    avgAccuracy = totalCorrects / len(dataloader.dataset)\n\n    # print(\"test loss\", avgLoss.to(\"cpu\").item()) # AttributeError: 'float' object has no attribute 'item'\n    print(\"test loss\", avgLoss)\n    print(\"test accuracy\", avgAccuracy)\n\n    return avgLoss, avgAccuracy","metadata":{"execution":{"iopub.status.busy":"2025-01-15T15:17:41.232365Z","iopub.execute_input":"2025-01-15T15:17:41.232576Z","iopub.status.idle":"2025-01-15T15:17:41.246601Z","shell.execute_reply.started":"2025-01-15T15:17:41.232557Z","shell.execute_reply":"2025-01-15T15:17:41.245759Z"},"id":"05f0bf97","papermill":{"duration":0.027335,"end_time":"2024-12-18T17:14:16.147775","exception":false,"start_time":"2024-12-18T17:14:16.120440","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":12},{"id":"f015a11f","cell_type":"code","source":"oldCols = [\"en\", \"fa\"]\ndatasetTrain, datasetVal = getDatasetsCSV(oldCols[0], oldCols[1], configs[\"english\"], configs[\"persian\"], configs[\"train_path\"], configs[\"val_path\"])\n\ngetPersianDs, getEnglishDs = getDsByLang(configs[\"persian\"], configs[\"english\"])\nprint(\"Before Preproccess: \", datasetTrain[0])\ndatasetTrain, datasetVal = applyPreprocess([datasetTrain, datasetVal], configs)\nprint(\"After Preproccess: \", datasetTrain[0])\ntrainDataloader = DataLoader(datasetTrain, batch_size=configs['batch_size'], shuffle=True)\nvalDataloader = DataLoader(datasetVal, batch_size=configs['batch_size'], shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2025-01-15T15:17:41.247554Z","iopub.execute_input":"2025-01-15T15:17:41.247810Z","iopub.status.idle":"2025-01-15T15:17:47.280072Z","shell.execute_reply.started":"2025-01-15T15:17:41.247790Z","shell.execute_reply":"2025-01-15T15:17:47.278921Z"},"id":"f015a11f","outputId":"097a4b25-fa28-46fb-f8b6-1f40cd04e488","papermill":{"duration":5.07707,"end_time":"2024-12-18T17:14:21.240389","exception":false,"start_time":"2024-12-18T17:14:16.163319","status":"completed"},"tags":[],"colab":{"referenced_widgets":["b960f341da70434eb5bb2f31a343fb42","f7cf88d749194b76b179b7b7760eb4fc","8b96faa300d041cb93fd08ba5004fd58","952b013f107c44d28aecfdefcdd7c75f","4d96bf61c21c4bc3b4350a99ef740c58","3abd1a8fd5174463ae1c7f694c0c713a","c50f5072a94a403b8065bdee2118ca58","2da916168417474c90f852f8c83f20cc","62a342a105e143c1b371718ce75acf21","4f0d1bc94f304ab79421f7e65d178bf0","bde48f1a3ab4497882576d5d2b9b31ef","c4ecfc272f5d49fa8692582a69b7e61c","7ec31a50f0524ed8b3bd515577a0c038","c7f1596aee54403680a00c37fb009681","b26b31daee2349e58dd7d4b80345e528","8ac084fcfaeb433ea59ec1647ab580b9","e8b90e2fdaa9489dad98e78e3f9ff79a","8fa18a97ef8c411a828c629e2c9795a7","ef7710287ec44b90ba31f22a1faa04f1","ca2e2cba5f3d48b7a03bf6311be41fad","6d5a19f86b9f462283d8af6cff99db74","5fee996710b1436c83722bc3ce3b2884"],"base_uri":"https://localhost:8080/","height":116},"trusted":true},"outputs":[{"name":"stdout","text":"Before Preproccess:  {'en': 'A person doing karate in a green business card.', 'fa': 'شخصی که کاراته انجام می دهد در کارت ویزیت سبز.'}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/59999 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ea5d8e8bf064b76bcc4c4dd3629564c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6cfba6586ae440e9b3dad2ad38080e51"}},"metadata":{}},{"name":"stdout","text":"After Preproccess:  {'en': 'a person doing karate in a green business card', 'fa': 'شخصی که کاراته انجام می دهد در کارت ویزیت سبز'}\n","output_type":"stream"}],"execution_count":13},{"id":"aea3bc61","cell_type":"markdown","source":"#### Tokenizers","metadata":{"id":"aea3bc61","papermill":{"duration":0.015811,"end_time":"2024-12-18T17:14:21.272664","exception":false,"start_time":"2024-12-18T17:14:21.256853","status":"completed"},"tags":[]}},{"id":"506ef8ec","cell_type":"code","source":"referenceTokenizer = open_clip.get_tokenizer(configs[\"reference_checkPoint\"])\n\ncandidateConfig = AutoConfig.from_pretrained(configs[\"candidate_checkpoint\"])\ncandidateTokenizer = AutoTokenizer.from_pretrained(configs[\"candidate_checkpoint\"])\n\nconfigs = configs | {\"candidate_embedding\" : candidateConfig.hidden_size}\n\nfaTokenPercentile = calcPrcentileTokens(datasetTrain, candidateTokenizer, configs[\"persian\"])\nfaTokenPercentile\n\nenTokenPercentile = calcPrcentileTokens(datasetTrain, referenceTokenizer, configs[\"english\"])\nenTokenPercentile\n\nconfigs = configs | {\"en_tok_percentile\" : enTokenPercentile}\nconfigs = configs | {\"fa_tok_percentile\" : faTokenPercentile}","metadata":{"execution":{"iopub.status.busy":"2025-01-15T15:17:47.282660Z","iopub.execute_input":"2025-01-15T15:17:47.282895Z","iopub.status.idle":"2025-01-15T15:17:59.450899Z","shell.execute_reply.started":"2025-01-15T15:17:47.282875Z","shell.execute_reply":"2025-01-15T15:17:59.450136Z"},"id":"506ef8ec","outputId":"ee2794e0-446a-4822-ebe7-e43da22c79bc","papermill":{"duration":10.512708,"end_time":"2024-12-18T17:14:31.801887","exception":false,"start_time":"2024-12-18T17:14:21.289179","status":"completed"},"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/611 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef83bcb9069d47ceb3e364a8760f8284"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/367 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eef98c02fc3440a9836763c29fb1d7af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/1.47M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a31452278ee04744876e55e6a0894772"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/4.31M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"192dafbc1d3f48fdbe523336ba6678eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d5507aecceb429c82c3f73f911ccdfa"}},"metadata":{}}],"execution_count":14},{"id":"d92d790a","cell_type":"markdown","source":"#### Models","metadata":{"id":"d92d790a","papermill":{"duration":0.016378,"end_time":"2024-12-18T17:14:31.835725","exception":false,"start_time":"2024-12-18T17:14:31.819347","status":"completed"},"tags":[]}},{"id":"0cfbc447","cell_type":"code","source":"referenceModel = TextEncoder(configs).to(configs[\"device\"])\ncandidateModel = CandidateModel(model_name=configs[\"candidate_checkpoint\"], unfreezeLayers=configs[\"unfreezed_layers\"]).to(configs[\"device\"])\nreferenceModel = freezeModel(referenceModel)\n\ncandidateModel.to(configs['device'])\nreferenceModel.to(configs['device'])\n\nmodels = {\n    \"referenceModel\" : referenceModel,\n    \"candidateModel\" : candidateModel\n}","metadata":{"execution":{"iopub.status.busy":"2025-01-15T15:17:59.451974Z","iopub.execute_input":"2025-01-15T15:17:59.452274Z","iopub.status.idle":"2025-01-15T15:18:30.615711Z","shell.execute_reply.started":"2025-01-15T15:17:59.452238Z","shell.execute_reply":"2025-01-15T15:18:30.614648Z"},"id":"0cfbc447","papermill":{"duration":28.039003,"end_time":"2024-12-18T17:14:59.891005","exception":false,"start_time":"2024-12-18T17:14:31.852002","status":"completed"},"tags":[],"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/877M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4bed8ccd2cc4979b892fb09b3ac9297"}},"metadata":{}}],"execution_count":15},{"id":"59bc9d96","cell_type":"markdown","source":"## Training\n### TODO (10pts) for running the code and (20pts) for achieving above 70 percent test accuracy","metadata":{"id":"59bc9d96","papermill":{"duration":0.0162,"end_time":"2024-12-18T17:14:59.924176","exception":false,"start_time":"2024-12-18T17:14:59.907976","status":"completed"},"tags":[]}},{"id":"03a0e5e7","cell_type":"code","source":"temperature = torch.nn.Parameter(torch.tensor(configs['temperature']).float())\noptimizer = torch.optim.AdamW(list(models['candidateModel'].parameters()) + [temperature], weight_decay=configs[\"weight_decay\"], lr=configs['lr'])\nlrScheduler = ReduceLROnPlateau(optimizer, 'max', patience=configs['patience'], factor=configs['factor'])","metadata":{"execution":{"iopub.status.busy":"2025-01-15T15:18:30.616648Z","iopub.execute_input":"2025-01-15T15:18:30.617258Z","iopub.status.idle":"2025-01-15T15:18:30.625128Z","shell.execute_reply.started":"2025-01-15T15:18:30.617224Z","shell.execute_reply":"2025-01-15T15:18:30.624022Z"},"id":"03a0e5e7","papermill":{"duration":0.025563,"end_time":"2024-12-18T17:14:59.966213","exception":false,"start_time":"2024-12-18T17:14:59.940650","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":16},{"id":"0a7f783c","cell_type":"code","source":"bestValAcc = float('-inf')\n\nmetrics = pd.DataFrame(columns=[\"Avg-train-loss\", \"Avg-train-accuracy\",\"Avg-val-loss\", \"Avg-val-accuracy\"])\n\nfor t in range(configs['epochs']):\n    trainLoss, trainAcc = trainLoop(trainDataloader, models, referenceTokenizer, candidateTokenizer, optimizer, temperature)\n    valLoss, valAcc = valLoop(valDataloader, models, referenceTokenizer, candidateTokenizer, temperature)\n\n    # metrics.loc[t+1] = [trainLoss.item(), trainAcc, valLoss.item(), valAcc] # AttributeError: 'float' object has no attribute 'item'\n    metrics.loc[t+1] = [trainLoss, trainAcc, valLoss, valAcc]  # No need for .item() \n\n    lrScheduler.step(valAcc)\n\n    print(\"Temperature at this epoch was :\", temperature.item())\n\nprint(f'Best accuracy of validation gained: ', bestValAcc)\nprint(\"Done!\")","metadata":{"execution":{"iopub.status.busy":"2025-01-15T15:18:30.626235Z","iopub.execute_input":"2025-01-15T15:18:30.626591Z","iopub.status.idle":"2025-01-15T17:28:57.693953Z","shell.execute_reply.started":"2025-01-15T15:18:30.626557Z","shell.execute_reply":"2025-01-15T17:28:57.692925Z"},"id":"0a7f783c","outputId":"10ad43fb-8074-4383-9e15-aa2eaff30922","papermill":{"duration":17782.445889,"end_time":"2024-12-18T22:11:22.429709","exception":false,"start_time":"2024-12-18T17:14:59.983820","status":"completed"},"tags":[],"colab":{"base_uri":"https://localhost:8080/","height":460},"trusted":true},"outputs":[{"name":"stdout","text":"Training Starts!\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 469/469 [20:07<00:00,  2.57s/it]\n","output_type":"stream"},{"name":"stdout","text":"train loss 0.013719451447526948\ntrain accuracy 0.6863447724128735\nTesting Starts!\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 157/157 [05:57<00:00,  2.28s/it]\n","output_type":"stream"},{"name":"stdout","text":"test loss 0.009109904989600182\ntest accuracy 0.83305\nTemperature at this epoch was : 20.052417755126953\nTraining Starts!\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 469/469 [20:07<00:00,  2.57s/it]\n","output_type":"stream"},{"name":"stdout","text":"train loss 0.008144417174305646\ntrain accuracy 0.8815146919115319\nTesting Starts!\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 157/157 [05:57<00:00,  2.28s/it]\n","output_type":"stream"},{"name":"stdout","text":"test loss 0.00723524771630764\ntest accuracy 0.89005\nTemperature at this epoch was : 20.10107421875\nTraining Starts!\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 469/469 [20:08<00:00,  2.58s/it]\n","output_type":"stream"},{"name":"stdout","text":"train loss 0.006466534717331056\ntrain accuracy 0.928065467757796\nTesting Starts!\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 157/157 [05:57<00:00,  2.28s/it]\n","output_type":"stream"},{"name":"stdout","text":"test loss 0.006321975046396255\ntest accuracy 0.9108\nTemperature at this epoch was : 20.147804260253906\nTraining Starts!\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 469/469 [20:08<00:00,  2.58s/it]\n","output_type":"stream"},{"name":"stdout","text":"train loss 0.0053124641263069105\ntrain accuracy 0.9573326222103702\nTesting Starts!\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 157/157 [05:57<00:00,  2.28s/it]\n","output_type":"stream"},{"name":"stdout","text":"test loss 0.005724597030878067\ntest accuracy 0.92445\nTemperature at this epoch was : 20.193313598632812\nTraining Starts!\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 469/469 [20:08<00:00,  2.58s/it]\n","output_type":"stream"},{"name":"stdout","text":"train loss 0.004491138764525591\ntrain accuracy 0.9742162369372823\nTesting Starts!\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 157/157 [05:57<00:00,  2.28s/it]","output_type":"stream"},{"name":"stdout","text":"test loss 0.005346008688211441\ntest accuracy 0.9297\nTemperature at this epoch was : 20.23788833618164\nBest accuracy of validation gained:  -inf\nDone!\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":17},{"id":"884ba162","cell_type":"code","source":"plotMetric(metrics, \"Avg-val-accuracy\")\nmetrics.tail(3)","metadata":{"execution":{"iopub.status.busy":"2025-01-15T17:28:57.695167Z","iopub.execute_input":"2025-01-15T17:28:57.695580Z","iopub.status.idle":"2025-01-15T17:28:58.061303Z","shell.execute_reply.started":"2025-01-15T17:28:57.695538Z","shell.execute_reply":"2025-01-15T17:28:58.060271Z"},"id":"884ba162","papermill":{"duration":0.494729,"end_time":"2024-12-18T22:11:23.078241","exception":false,"start_time":"2024-12-18T22:11:22.583512","status":"completed"},"tags":[],"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"   Avg-train-loss  Avg-train-accuracy  Avg-val-loss  Avg-val-accuracy\n3        0.006467            0.928065      0.006322           0.91080\n4        0.005312            0.957333      0.005725           0.92445\n5        0.004491            0.974216      0.005346           0.92970","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Avg-train-loss</th>\n      <th>Avg-train-accuracy</th>\n      <th>Avg-val-loss</th>\n      <th>Avg-val-accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>0.006467</td>\n      <td>0.928065</td>\n      <td>0.006322</td>\n      <td>0.91080</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.005312</td>\n      <td>0.957333</td>\n      <td>0.005725</td>\n      <td>0.92445</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.004491</td>\n      <td>0.974216</td>\n      <td>0.005346</td>\n      <td>0.92970</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":18},{"id":"732adf00","cell_type":"markdown","source":"## Question Box (10pts + 5pts bonus)\n\n1- Do we even need normalization for tasks like this? will they provide any accuracy gain? write what you think.\n\nNormalization is indeed important for tasks like this because:\n- It helps stabilize training by keeping the input distributions consistent\n- Reduces internal covariate shift\n- Makes the model less sensitive to initialization\n- Helps with gradient flow during backpropagation\n- Particularly important in contrastive learning where we're comparing embeddings\n\nIn other words, Normalization is crucial for tasks like this because it ensures that the embeddings are on a consistent scale, which helps in computing meaningful similarity scores. Without normalization, the magnitudes of the embeddings could dominate the similarity calculations, leading to suboptimal performance. Normalization can improve accuracy by ensuring that the model focuses on the direction of the embeddings rather than their magnitudes.\n\nIn summary, Normalization techniques like batch normalization and layer normalization are crucial in stabilizing and accelerating the training process. They help in reducing internal covariate shift, leading to smoother convergence and potentially higher accuracy by making the optimization landscape more regular.\n\n<br/>\n2- When training a neural network, what takes the memory? mention at least 4 things.\n\n- Model parameters (weights and biases)\n- Activations of intermediate outputs of each layer during forward pass (needed for backprop)\n- Optimizer states introduces additional memory used by optimizers (e. g. momentum in SGD)\n- Batch of input data and labels and intermediate representations for each batch\n- Gradients for each parameter during backward pass used for updating the model parameters\n- Cache for gradient computation\n- GPU buffers and temporary storage\n- Memory fragments due to allocation/deallocation\n\n<br/>\n\n3- find out the actual Open AI's training configuration of Clip model.\n\n- Batch Size: 32,768\n- Vocabulary size: 49,408\n- Epochs: 32\n- Learning Rate: 5e-4\n- Maximum temperature: 100\n- Temperature parameter: Learned during training\n- Dataset: 400 million image-text pairs for training\n- Optimizer: AdamW with weight decay (β1=0.9, β2=0.999 (ResNet), 0.98 (ViT), ε=1e-8 (ResNet), 1e-6 (ViT))\n- Weight decay: 0.2\n- Warm-up iterations: 2000\n- Cosine learning rate decay\n\n#### Bonus\n4- We have an alternative clip's loss implementation, write its pseudocode.\n\n*Here is the originial Numpy-like pseudocode for the core of an implementation of CLIP that is mentioned in the originial paper titeled Learning Transferable Visual Models From Natural Language Supervision:*\n\n```\n# image_encoder - ResNet or Vision Transformer\n# text_encoder - CBOW or Text Transformer\n# I[n, h, w, c] - minibatch of aligned images\n# T[n, l] - minibatch of aligned texts\n# W_i[d_i, d_e] - learned proj of image to embed\n# W_t[d_t, d_e] - learned proj of text to embed\n# t - learned temperature parameter\n\n# extract feature representations of each modality\nI_f = image_encoder(I) #[n, d_i]\nT_f = text_encoder(T) #[n, d_t]\n\n# joint multimodal embedding [n, d_e]\nI_e = l2_normalize(np.dot(I_f, W_i), axis=1)\nT_e = l2_normalize(np.dot(T_f, W_t), axis=1)\n\n# scaled pairwise cosine similarities [n, n]\nlogits = np.dot(I_e, T_e.T) * np.exp(t)\n\n# symmetric loss function\nlabels = np.arange(n)\nloss_i = cross_entropy_loss(logits, labels, axis=0)\nloss_t = cross_entropy_loss(logits, labels, axis=1)\nloss = (loss_i + loss_t)/2\n```\n\nAnd here is my pseudocode for CLIP Loss:\n1. Normalize text and image embeddings.\n2. Compute similarity matrix:\n   - similarity[i][j] = dot(text_embedding[i], image_embedding[j])\n3. Scale similarity matrix by temperature.\n4. Calculate cross-entropy loss:\n   - Text-to-image loss:\n     CrossEntropyLoss(similarity, target: diagonal indices)\n   - Image-to-text loss:\n     CrossEntropyLoss(similarity.T, target: diagonal indices)\n5. Final loss = (Text-to-image loss + Image-to-text loss) / 2","metadata":{"id":"732adf00","papermill":{"duration":0.148084,"end_time":"2024-12-18T22:11:23.388751","exception":false,"start_time":"2024-12-18T22:11:23.240667","status":"completed"},"tags":[]}},{"id":"dcd8efa7","cell_type":"code","source":"def clip_loss_alternative_implementation(image_embeddings, text_embeddings, temperature):\n    # Normalize text and image embeddings\n    image_embeddings = normalize(image_embeddings)\n    text_embeddings = normalize(text_embeddings)\n\n    # Compute similarity matrix and Scale similarity matrix by temperature\n    logits = (image_embeddings @ text_embeddings.T) * exp(temperature)\n\n    # Create targets (diagonal matrix for positive pairs)\n    batch_size = logits.size(0)\n    targets = torch.arange(batch_size).to(device)\n\n    # Compute cross-entropy loss ((Text-to-image loss + Image-to-text loss) / 2)\n    loss = (cross_entropy(logits, targets) + cross_entropy(logits.T, targets)) / 2\n\n    return loss","metadata":{"id":"dcd8efa7","papermill":{"duration":0.152521,"end_time":"2024-12-18T22:11:23.693977","exception":false,"start_time":"2024-12-18T22:11:23.541456","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T17:28:58.062383Z","iopub.execute_input":"2025-01-15T17:28:58.062654Z","iopub.status.idle":"2025-01-15T17:28:58.067735Z","shell.execute_reply.started":"2025-01-15T17:28:58.062631Z","shell.execute_reply":"2025-01-15T17:28:58.066839Z"}},"outputs":[],"execution_count":19}]}